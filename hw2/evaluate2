#!/usr/bin/env python
import argparse # optparse is deprecated
from itertools import islice # slicing for iterators
from nltk.parse import stanford
from scipy import stats
from nltk import tokenize
import string
from nltk.tokenize import word_tokenize

# DRY
def word_matches(h, ref):
    return sum(1 for w in h if w in ref)
    # or sum(w in ref for w in f) # cast bool -> int
    # or sum(map(ref.__contains__, h)) # ugly!
    
    
#  
def meteorScore(hyp, ref):
    hyp = " ".join(hyp)
    hyp = hyp.decode('utf-8')
    hypToken = [w.lower().strip() for w in word_tokenize(hyp) if w.isalnum() ] # any (c.isalnum() for c in w)
    ref = " ".join(ref)
    ref = ref.decode('utf-8')
    refToken = [w.lower().strip() for w in word_tokenize(ref) if w.isalnum() ]
    m = sum([1.0 for w in hypToken if w in refToken])

    try:
        precision = m / len(hypToken)
        recall = m / len(refToken)
        fmean = (10.0*precision*recall) / (7.0*recall + 3.0 * precision)
        #fmean = stats.hmean([precision, recall])
        return fmean
    except:
        return 0
    
def bleuScore(hyp, ref):
    hyp = " ".join(hyp)
    hyp = hyp.decode('utf-8')
    hypToken = [w.lower().strip() for w in word_tokenize(hyp) if w.isalnum() ] # any (c.isalnum() for c in w)
    bigrams = [b for b in zip(hypToken[:-1], hypToken[1:])]
    print(bigrams)
    ref = " ".join(ref)
    ref = ref.decode('utf-8')
    refToken = [w.lower().strip() for w in word_tokenize(ref) if w.isalnum() ]
    m = sum([1.0 for w in hypToken if w in refToken])

    try:
        precision = m / len(hypToken)
        
    except:
        return 0
def main():
    parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
    # PEP8: use ' and not " for strings
    parser.add_argument('-i', '--input', default='data/train-test.hyp1-hyp2-ref',
            help='input file (default data/train-test.hyp1-hyp2-ref)')
    parser.add_argument('-n', '--num_sentences', default=None, type=int,
            help='Number of hypothesis pairs to evaluate')
    # note that if x == [1, 2, 3], then x[:None] == x[:] == x (copy); no need for sys.maxint
    opts = parser.parse_args()
 
    def sentences():
        with open(opts.input) as f:
            for pair in f:
                yield [sentence.strip().split() for sentence in pair.split(' ||| ')]
      
    
    for h1, h2, ref in islice(sentences(), opts.num_sentences):
        #h1_match = word_matches(h1, rset)
        #h2_match = word_matches(h2, rset)
        meteor1 = meteorScore(h1, ref)
        meteor2 = meteorScore(h2, ref)
        bleu1 = bleuScore(h1, ref)
        print(-1 if meteor1 > meteor2 else # \begin{cases}
            (0 if meteor1 == meteor2
              else 1)) # \end{cases}
    # we create a generator and avoid loading all sentences into a list
#     def sentences():
#         with open(opts.input) as f:
#             for pair in f:
#                 yield [sentence.strip().split() for sentence in pair.split(' ||| ')]
#                 
#             
#             
#             
#  
#     # note: the -n option does not work in the original code
#     for h1, h2, ref in islice(sentences(), opts.num_sentences):
#         rset = set(ref)
#         h1_match = word_matches(h1, rset)
#         h2_match = word_matches(h2, rset)
#         print(-1 if h1_match > h2_match else # \begin{cases}
#                 (0 if h1_match == h2_match
#                     else 1)) # \end{cases}
#  
# convention to allow import of this file as a module
if __name__ == '__main__':
    main()
