#!/usr/bin/env python
import optparse
import sys
from collections import defaultdict
from _collections import defaultdict
from math import log
import datetime


def rawCounts(bitext):
	f_count = defaultdict(int)
	e_count = defaultdict(int)
	fe_count = defaultdict(int)
	#Get raw counts.
	for (n, (f, e)) in enumerate(bitext):
		for f_i in f:
			f_count[f_i] += 1
			for e_j in e:
				fe_count[(f_i,e_j)] += 1
		for e_j in e:
			e_count[e_j] += 1
		if n % 500 == 0:
			sys.stderr.write(".")
	return f_count, e_count, fe_count




def initialize(bitext):
	probsF = defaultdict(float)
	probsE = defaultdict(float)

	f_count = defaultdict(int)
	e_count = defaultdict(int)

	
	for (n, (f, e)) in enumerate(bitext):
		for f_i in f:
			f_count[f_i] += 1
		for e_i in e:
			e_count[e_i] += 1
	#Initialize probabilites for EM
	for (n, (f, e)) in enumerate(bitext):
		for f_i in set (f):
			for e_i in set (e):
				probsF[f_i,e_i] = 1.0/len(f_count)
				probsE[f_i,e_i] = 1.0/len(e_count)
		if n % 5000 == 0:
			sys.stderr.write(".")
	return probsF, probsE

def eStep1(bitext, probs):
	expected_counts_1 = defaultdict(int)
	total_counts_1 = defaultdict(int)
	expected_counts_2 = defaultdict(int)
	total_counts_2 = defaultdict(int)
	actualCounts = defaultdict(int)

	#E step
	for (n, (f, e)) in enumerate(bitext):
		normF = defaultdict(int)
		for f_i in set(f):
			for e_i in set(e):
				normF[f_i] += probs[f_i, e_i]
		for e_i in set(e):
			normTerm = 0
			for f_i in set(f):
				normTerm += probs[f_i, e_i]
			for f_i in set(f):
				term = probs[f_i, e_i] / normTerm
				expected_counts_1[f_i, e_i] += term
				total_counts_1[f_i] += term
				
				term2 =  probs[f_i, e_i] /  normF[f_i]
 				expected_counts_2[f_i, e_i] += term2
 				total_counts_2[e_i] += term2		
 				
 				actualCounts[f_i, e_i] += 1		
# 		for f_i in set(f):
# 			normTerm = 0
# 			for e_i in set(e):
# 				normTerm += probs[f_i, e_i]
# 			for e_i in set(e):
# 				term = probs[f_i, e_i] / normTerm
# 				expected_counts_2[f_i, e_i] += term
# 				total_counts_2[e_i] += term
		if n % 5000 == 0:
			sys.stderr.write("e")
			
	return expected_counts_1, total_counts_1, expected_counts_2, total_counts_2, actualCounts


def mStep(bitext, expected_counts_1, expected_counts_2, total_counts_1, total_counts_2, actualCounts):
	probs = defaultdict(float)
	#M step
# 	for (n, (f, e)) in enumerate(bitext):
# 		for f_i in set(f):
# 			for e_i in set(e):
# 				term1 = (expected_counts_1[f_i, e_i] / total_counts_1[f_i])
# 				term2 = (expected_counts_2[f_i, e_i] / total_counts_2[e_i]) #(expected_counts_1[f_i, e_i] / total_counts_1[f_i]) + (expected_counts_2[f_i, e_i] / total_counts_2[e_i])
# 				probs[f_i, e_i] = (0.5*term1) + (0.5*term2)
	n = 0
	for f_i, e_i in expected_counts_1:
		term1 = (expected_counts_1[f_i, e_i] / total_counts_1[f_i]) * actualCounts[f_i, e_i]
		term2 = (expected_counts_2[f_i, e_i] / total_counts_2[e_i]) * actualCounts[f_i, e_i] #(expected_counts_1[f_i, e_i] / total_counts_1[f_i]) + (expected_counts_2[f_i, e_i] / total_counts_2[e_i])
		probs[f_i, e_i] = (0.5*term1) + (0.5*term2)
		n += 1
		if n % 5000000 == 0:
			sys.stderr.write("m")
	return probs

def runEM(bitext, probsF, probsE, iterations):
	probs = probsF
	sys.stderr.write("\n" + str(datetime.datetime.now()) + "\n")

	for i in range (iterations):
		sys.stderr.write("\nBeginning EM iteration %i" % (i))

			
		expected_counts_1, total_counts_1, expected_counts_2, total_counts_2, actualCounts = eStep1(bitext, probs)
		probs = mStep(bitext, expected_counts_1, expected_counts_2, total_counts_1, total_counts_2, actualCounts)
		getAlignments(probs, bitext, i)
		sys.stderr.write("\n" + str(datetime.datetime.now()) + "\n")
		
	return probs


def getAlignments(probs, bitext, iteration = None):
	alignments = []
	for (_, (f, e)) in enumerate(bitext):
		sentAlign = []
		for eindex in range(len(e)):#e_i in e:
			e_i = e[eindex]
			maxScore = 0
			bestPos = set()
			
			for findex in range(0,len(f)):
				if (probs[f[findex], e_i]  > maxScore):
					maxScore = probs[f[findex], e_i]
					bestPos.clear()
					bestPos.add(findex)
				if (probs[f[findex], e_i]  == maxScore):
					bestPos.add(findex)
			if (len(bestPos) == 1):
				sentAlign.append(bestPos.pop())
			else:
				closestPos = 0
				closestDist = len(e)
				for pos in bestPos:
					if (abs(pos - eindex) < closestDist):
						closestDist = abs(pos - eindex)
						closestPos = pos
				sentAlign.append(closestPos)
# 		for e_i in e:
# 			maxScore = 0
# 			bestPos = 0
# 			
# 			for findex in range(0,len(f)):
# 				if (probs[f[findex], e_i]  > maxScore):
# 					maxScore = probs[f[findex], e_i]
# 					bestPos = findex
# 				
# 			sentAlign.append(bestPos)
		alignments.append(sentAlign)
	if (iteration != None):
		printAlignmentsIter(alignments, iteration)
		
	return alignments



def printAlignmentsIter(alignments, iteration):
	f = open("align4_" + str(iteration) + ".txt", "w")
 	for a in alignments:
  		for i in range(len(a)):
  			f.write("%i-%i " % (a[i], i))
		f.write("\n")
		
def printAlignments(alignments):
 	for a in alignments:
  		for i in range(len(a)):
  			sys.stdout.write("%i-%i " % (a[i], i))
		sys.stdout.write("\n")		

def align(opts):
	sys.stderr.write("Training with IBM-1...")
	bitext = [[sentence.strip().split() for sentence in pair.split(' ||| ')] for pair in open(opts.bitext)][:opts.num_sents]
	
	#f_count, _, _ = rawCounts(bitext)
	probsF, probsE = initialize(bitext)

	#Run EM
	probs = runEM(bitext, probsF, probsE, opts.iterations)

	alignments = getAlignments(probs, bitext)
	
	printAlignments(alignments)



if __name__ == '__main__':
	
	optparser = optparse.OptionParser()
	optparser.add_option("-b", "--bitext", dest="bitext", default="data/dev-test-train.de-en", help="Parallel corpus (default data/dev-test-train.de-en)")
	optparser.add_option("-i", "--iterations", dest="iterations", default=5, type="int", help="Iterations of EM")
	optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint, type="int", help="Number of sentences to use for training and alignment")
	(opts, _) = optparser.parse_args()
	align(opts)


			
			
'''
dice = defaultdict(int)
for (k, (f_i, e_j)) in enumerate(fe_count.keys()):
  dice[(f_i,e_j)] = 2.0 * fe_count[(f_i, e_j)] / (f_count[f_i] + e_count[e_j])
  if k % 5000 == 0:
	sys.stderr.write(".")
sys.stderr.write("\n")

for (f, e) in bitext:
  for (i, f_i) in enumerate(f): 
	for (j, e_j) in enumerate(e):
	  if dice[(f_i,e_j)] >= opts.threshold:
		sys.stdout.write("%i-%i " % (i,j))
  sys.stdout.write("\n")
'''
			